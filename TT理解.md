解释一下TT核心中的维度结构：

每个TT核心是一个三维张量，其结构为 [rk-1 × nk × rk]，其中：

```text
1. rk-1：左TT秩（前一个rank）
2. nk：当前维度的mode大小（输入维度大小）
3. rk：右TT秩（后一个rank）
```

以一个具体例子解释：
```cpp
// 假设有3个维度的TT分解
TTConfig config(
    3,                          // 维度数
    {1, 16, 32, 1},            // ranks: r0,r1,r2,r3
    {64, 32, 128},             // input_modes: n1,n2,n3
    {32, 64, 64}               // output_modes: m1,m2,m3
);

// 每个核心的维度结构:
Core1: [r0×n1×r1×m1] = [1 × 64 × 16 × 32]
Core2: [r1×n2×r2×m2] = [16 × 32 × 32 × 64]
Core3: [r2×n3×r3×m3] = [32 × 128 × 1 × 64]
```

所以mode实际指的是：
1. input_modes：每个维度的输入特征大小(nk)
2. output_modes：每个维度的输出特征大小(mk)

rank(rk)是不同的概念：
- 它控制TT分解的压缩率
- 连接相邻核心之间的维度
- r0和rd必须等于1

因此每个核心实际是四维张量[rk-1 × nk × rk × mk]，包含：
- 两个rank维度(rk-1,rk)
- 一个输入mode维度(nk)
- 一个输出mode维度(mk)

###  **关键点：为什么要有四维？**

如果TT核心只用于存储张量，那么三维结构足够。但如果要应用于更复杂的任务（如网络层输入/输出特征转换），就需要加入额外的维度（mk，输出mode），因此扩展为四维张量。

下一步：添加自定义的output和input的mode_size



### **模型复杂度**

- nk和 mk 的大小直接影响TT核心的张量大小

  

  - 如果 nk 和 mk 较大，核心的存储需求和计算量都会增加。
  - 模式大小越大，模型的表达能力越强，但计算和存储成本也更高。

